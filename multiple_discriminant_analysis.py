# -*- coding: utf-8 -*-
"""multiple_discriminant_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LJfjU5sRUGYKqlkwmEYUw63kDuAUTwCh
"""

import scipy.io as scio
import numpy as np
from math import pi,sqrt,exp,pow
#read the training and label file
training_file = '/content/drive/MyDrive/Colab Notebooks/ml_ca/Data_Train.mat'
training_dict = scio.loadmat(training_file)
training_data = training_dict["Data_Train"]

label_file = '/content/drive/MyDrive/Colab Notebooks/ml_ca/Label_Train.mat'
label_dict = scio.loadmat(label_file)
label = label_dict["Label_Train"]

test_file = '/content/drive/MyDrive/Colab Notebooks/ml_ca/Data_test.mat'
test_dict = scio.loadmat(test_file)
test_data = test_dict["Data_test"]

#classify the training data to 3 classes
c = training_data
c1 = []
c2 = []
c3 = []
for i in range(len(training_data)):
  if label[i] == 1:
    c1.append(list(training_data[i]))
  elif label[i] == 2:
    c2.append(list(training_data[i]))
  elif label[i] == 3:
    c3.append(list(training_data[i]))
c1 = np.array(c1)
c2 = np.array(c2)
c3 = np.array(c3)

#1. calculate the mean vector for each class and total mean vector
def cal_mean(c):
  sum_x = [0]
  for x_k in c:
    sum_x += x_k
  mean = sum_x/len(c)
  return mean

#mean_1 = np.array([cal_mean(c1)])
#mean_2 = np.array([cal_mean(c2)])
#mean_3 = np.array([cal_mean(c3)])
#mean_total = np.array([cal_mean(c)])

#2. calculate Sw and Sb
def cal_Si(c):
  mean = cal_mean(c)
  Si = [0]
  for x_k in c:
    a = np.array([x_k-mean])
    Si += np.dot(a.T,a)
  return Si

#S1 = cal_Si(c1)
#S2 = cal_Si(c2)
#S3 = cal_Si(c3)
#Sw = S1+S2+S3
#print(Sw)

def cal_St(c):
  mean = cal_mean(c)
  St = [0]
  for x_k in c:
    a = np.array([x_k-mean])
    St += np.dot(a.T,a)
  return St  

#St = cal_St(c)
#Sb = St - Sw

"""def cal_Sb(c,c1,c2,c3):
  mean_1 = np.array([cal_mean(c1)])
  mean_2 = np.array([cal_mean(c2)])
  mean_3 = np.array([cal_mean(c3)])
  mean_total = np.array([cal_mean(c)])
  a = mean_1-mean_total
  b = mean_2-mean_total
  c = mean_3-mean_total
  S_b1 = np.dot(a.T,a)
  S_b2 = np.dot(b.T,b)
  S_b3 = np.dot(c.T,c)
  Sb = len(c1)*S_b1+len(c2)*S_b2+len(c3)*S_b3
  #Sb = S_b1+S_b2+S_b3
  return Sb
#Sb = cal_Sb(c,c1,c2,c3)
#print(Sb)
"""

#3. find the generalized eigenvalues and vectors
#Sw_inv = np.linalg.pinv(Sw)
#M = np.dot(Sw_inv,Sb)
#print("Sw_inv*Sb = \n",M)
#eig_val, eig_vec = np.linalg.eig(M)

#find the largest 2 eig_val and eig_vec
import heapq

#4. project samples on w1 and w2, and get w0_1 and w0_2
def cal_projected_mean(w,c):
  sum_projected_x = [0]
  for x_k in c:
    sum_projected_x += np.dot(w,x_k.T)
  projected_mean = sum_projected_x/len(c)
  return projected_mean

#find the most seperated class
def find_farthest(m1,m2,m3):
  a = np.array([m1,m2,m3])
  d1 = abs(a[0]-a[1])+abs(a[0]-a[2])
  d2 = abs(a[1]-a[0])+abs(a[1]-a[2])
  d3 = abs(a[2]-a[1])+abs(a[2]-a[0])
  b = [d1,d2,d3]
  sep_class = map(b.index, heapq.nlargest(1, b))
  c = list(sep_class)
  return a[c[0]],c[0]

#find the relative class in order to get w0
#m is the projected mean of the aimed class, m1 and m2 is the others
def cal_w0(m,m1,m2,m3):
  if m == m1:
    m1,m2 = m2,m3
  elif m == m2:
    m1,m2 = m1,m3
  elif m == m3:
    m1,m2 = m1,m2
  else:
     raise Exception("Error1!")

  if m-m1 <= m-m2:
    return -0.5*(m+m1)
  else:
    return -0.5*(m+m2)

#6. define the discriminant functions
def g(w,x,w0):
  a = np.dot(w,x.T)+w0
  return a

#7. define decision rule
#class_1 represent the predicted class of w1
#class_2 represent the predicted class of w2

def decision(x_k,c,c1,c2,c3):
  mean_1 = np.array([cal_mean(c1)])
  mean_2 = np.array([cal_mean(c2)])
  mean_3 = np.array([cal_mean(c3)])
  mean_total = np.array([cal_mean(c)])

  S1 = cal_Si(c1)
  S2 = cal_Si(c2)
  S3 = cal_Si(c3)
  Sw = S1+S2+S3

  St = cal_St(c)
  Sb = St - Sw

  Sw_inv = np.linalg.inv(Sw)
  M = np.dot(Sw_inv,Sb)
  eig_val, eig_vec = np.linalg.eig(M)

  a = eig_val.tolist()
  l_i = list(map(a.index, heapq.nlargest(2, a))) #list of the 2 largest eig_val' index
  w_1 = eig_vec[:,l_i[0]]
  w_2 = eig_vec[:,l_i[1]]

  #for w1, calculate the projected mean for 3 classes
  m11 = cal_projected_mean(w_1,c1)
  m12 = cal_projected_mean(w_1,c2)
  m13 = cal_projected_mean(w_1,c3)

  m1,_ = find_farthest(m11,m12,m13)
  w0_1 = cal_w0(m1,m11,m12,m13)

  #for w2, calculate the projected mean for 3 classes
  m21 = cal_projected_mean(w_2,c1)
  m22 = cal_projected_mean(w_2,c2)
  m23 = cal_projected_mean(w_2,c3)

  m2,_ = find_farthest(m21,m22,m23)
  w0_2 = cal_w0(m2,m21,m22,m23)

  _,class_1 = find_farthest(m11,m12,m13)
  _,class_2 = find_farthest(m21,m22,m23)
  total = [0,1,2]
  class_3 = [i for i in total if i != class_1 and i!= class_2]
  class_3 = class_3[0]
  class_1 += 1
  class_2 += 1
  class_3 += 1

  g1 = g(w_1,x_k,w0_1)
  g2 = g(w_2,x_k,w0_2)

  if g1>=0 and g2<=0:
    x = class_1
  elif g1<=0 and g2>=0:
    x = class_2
  elif g1<=0 and g2<=0:
    x = class_3
  elif g1>=0 and g2>=0:
    if g1>=g2:
      x = class_1
    else:
      x = class_2
  else:
    raise Exception("Error2!")

  return x

#try on the training set
def test(dataset,label):
  correct = 0
  result = []
  for i in range(len(dataset)):
    x_k = dataset[i]
    out = decision(x_k,c,c1,c2,c3)
    result.append(out)
  label = list(label)
  #print(result)
  for i in range(len(result)):
    if result[i] == label[i]:
      correct+=1
  accuracy = correct/len(dataset)
  return accuracy
accuracy = test(training_data,label)
print("The prediction accuracy on the training dataset = %.2f%%" %(accuracy*100))

#inference on the test_dataset
def predict(dataset):
  result = []
  for i in range(len(dataset)):
    x_k = dataset[i]
    out = decision(x_k,c,c1,c2,c3)
    result.append(out)
  return result

pred = predict(test_data)
print(pred)

#save the predction result of test dataset
pred=np.array(pred)
np.savetxt("/content/drive/MyDrive/Colab Notebooks/ml_ca/pred_LDA.csv",pred,fmt="%i")